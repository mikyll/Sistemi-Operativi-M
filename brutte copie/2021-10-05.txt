<!-- lezione 2021/10/05 -->

03 - Programmazione Concorrente

Quando parliamo di prog concorrente:insieme delle tecniche, metodologie e strumenti per il supporto all'esecuzione di sistemi soft composti da **insiemi di attività svolte simultaneamnete**

vari temi: non solo sviluppo di app concorrenti, ma anche tema di come queste possono essere supportate dal sistema di elaborazione.

Cenni di storia

origine in anni '60, nasce proprio nell'ambito dei Sistemi Operativi

Introduzione dei canali o controllori di dispositivi:

Naturalmentel'interazione tra dispositivi ed unità centrale di elaborazione è basta su meccanismo delle interruzioni (interrupt)

quando parliamo di esecuz di operazione a livello di IO consente di realizzare una forma di interazione tra la periferica e la CPU, che al ricevimento ditale segnale può tempestivamente gestire l'evento (es: trasferimento di dati).

Questo meccanismo di interruzioni è stato utilizzato ampiamente in sistemi multiprogrammati time-sharing, in cui è implementato il concetto di quanto tempo, che può essere condiviso.

Quanto di tempo assegnato ad una certa applicazione

"scatto di esecuzione"

molti programmi possono eseguire in un sistema time-sharing in ordine non predicibile (app concorrenti sono non deterministiche: lo stesso programma eseguito in tempi diversi può comportare risultati diversi)
Ciò si rileva anche quando parti di programmi condividono delle stesse variabili comuni: in cui si possono creare delle interferenze.


Successivamente sistemi multiprocessore. Nei primi sistemi concorrenti, in cui era previsto l'avanzamento simultaneo di più applicazioni contemporaneamanete, quello che prima era un parallelismo virtuale, poi è diventato anche un parallelismo "reale" in quanto si è arrivati ad avere dei processori con diversi core (microprocessori)

Vantaggio in termini di prestazione: quello che prima doveva essere portato avanti con un modello di parall virtuale, in cui la CPU si divideva in tutte le app concorrenti presenti sul sistema, qui diventa reale ed i tempi di esecuzione si abbattono.

quando ci proviamo in un sistema concorrente 

-con quale criterio modellare l'applicazione concorrente?

-Come suddividerla in attività concorrenti? (quanti processi utilizzare)

-Tema della possibilità delle interazioni tra queste diverse attività concorrenti
In generale le attività nelle quali si scompone l'applicazione, possono aver bisogno di interagire fra di loro. Ad esempio imporre dei vincoli di precedenza (sincronizzazione).

queste decisioni dipendono da diversi fattori: tipo di architettura hw, e tipo di applicazione.

di seguito qualche immagine che esprime i diversi tipi di architettura:
PROCESSORE SINGOLO
processore singolo (tipicamente 2 livelli di cache)

MULTIPROCESSORE
multiprocessore (ciascun core ha le proprie cache). Più comune al giorno d'oggi.
Nei pc di ultima generazione le cache sono di 3 livelli, ciascuna delle quali ha velocità e dimensioni diverse.

Ogni nodo (microprocessore) ha la possibilità di accedere a qualunque parte della memoria, grazie alla rete di interconnessione.

Categorizzazione: 2 modelli
- UMA (Uniform Memory Access), sistemi con numero ridotto di processori (da 2 a 30 circa). Sono caratterizzati da:
	- interconnessione realizzata tipicamente da memory bus o crossbar switch;
	- tempo di accesso alla memoria uniforme (qualunque il processore e qualunque sia la cella di memoria da accedere, il tempo di accesso è costante)
	- sono chiamati anche SMP (Symmetric MultiProcessors)

- NUMA (Non Uniform Memory Access), sistemi con un numero elevato di processori (decine o centinaia):
	- la memoria è organizzata gerarchicamente per evitare la congestione del bus;
	- la rete di interconnessione è strutturata anch'essa in modo gerarchico (insieme di switch e memorie ad albero, in cui ci sono parti di memoria più vicine a certi processori ed altre più lontane);
	- come dice il nome, il tempo di accesso dipende dalla distanza tra processore e memoria.

DISTRIBUTED-MEMORY
Rientrano in questa categoria i Multicomputers e Network Systems
non c'è memoria condivisa tra i nodi di elaborazione

La memoria è specifica del processore a cui è stata associata.
Non è possibile che un nodo di elaborazione possa fare riferimento alla memoria di un altro nodo.

C'è comunque bisogno di garantire la comunicazione tra i nodi, e quindi anche in queto caso c'è una rete di comunicazione.

Modello Multicomputer e modello network systems

Multicomputer:
Modello in cui i nodi e la rete sono fisicamente vicini (tipicamente nello stesso cabinet/struttura fisica), ad esempio sistema cluster:
è un insieme di nodi, tipicamente detti server, fisicamente vicini. Ogni nodo è una scheda inserita in una struttura fisica (Rack), dove solitamente la rete di interconnessione è una linea ad alta velocità con una larghezza di banda sufficientemente ampia.
Oltre ai cluster vi fanno parte anche i sistemi ad alto parallelismo (sistemi HPC)
Multicomputer sono fatti per essere aggregati in una stessa struttura fisica.


differenza tra questo modello e l'altro 
Network systems: sistemi in cui l'accoppiamento è più vasto rispetto al caso precedente, proprio a livello geografico.


slide 10
classificazione delle architetture, con riferimento alla tassonomia di Flynn (1972)
in cui vengono inquadrate architetture e sistemi di elab secondo 2 parametri:
1. distingue parallelismo a livello di istruzioni. In un sistema di questo tipo, abbiamo 2 possibilità:
	- **single instruction stream**, può essere eseguito un solo singolo flusso di istruzioni;
	- **multiple instruction streams**, possono essere eseguiti flussi di istruzioni multipli.
2. parallelismo a livello di dati:
	- **single data stream**, l'architettura durante l'esecuzione è in grado di elaborare un singolo flusso sequenziale di dati;
	- **multiple data streams**: l'architettura è in grado di processare più flussi di dati in parallelo.
	
*foto Flynn Tassonomy slide 11*

SISD - Singel Instruction, Multiple Data (streams
sistemi monoprocessore che fanno riferimento all'architettura classica della macchina di von newman.

SIMD - Single Instruction, Multiple Data (streams)

10:49
- parla delle GPU


nelle GPU, modello SIMD molto efficace, in quanto si hanno matrici di dati molto grandi (immagini)

in questa categoria rientrano i vector processors (tante unità di elaborazione, non troppo potenti, ma che messe insieme e se controllate opportunamente possono risolvere particolari classi di problemi in modo molto veloce

MIND - Multiple Instruction, Multiple Data (streams)

Insieme di nodi di  elab ognuno dei quali può eseguire flussi di istruzioni diverse su dati diversi.

ogni nodo del sistema può essere utilizzato da un processo che fa cose diverse su dati diversi.

all'interno di questa categoria rientrano i multiprocessori ma anche i multi computers.



MISD - Multiple Instruction, Single Data (streams)

singolo flusso di dati che allo stesso tempo può essere manipolato con diverse istruzioni.

A livello di sistemi di elaborazione non abbiamo sistemi significativi da portare.
Potrebbe essere il caso di "computer pipelined".
Ci sono diverse unità di elaborazione messe in cascata (in pipeline), che lavora su quel flusso ognuno facendo qualcosa di diverso.


slide 13
SIMD
le architetture di questa categoria hanno l'obbiettivo di risolvere in modo più veloce possibile problemi matriciali, nei quali i dati sono rappresentati in forma vettoriale o matriciale, e a livello architetturale, un esempio di come potrebbe essere strutturato un esempio di questa categoria sono i ray processors, in cui rientrano anche le GPU.

Ci sono tante unità di elaborazione, con la capacità ognuna di lavorare su dati diversi ad ogni istante, ma controllati da una singola control unit, che lavora in modo sequenziale, dunque impartirà ad ogni ciclo una certa istruzione a tutti i ...



slide 15
Applicazioni

Torniamo al discorso di partenza: come il progetto di app concorrenti dev'essere portato avavnti? dipende innanzitutto dal tipo di architettura, ma anche daivincoli del sistema operativo.

Tipi:
a) app che forniscono modello multithreaded
-strutturata come un insieme di processi (thread) che:
	- permette di dominare la complessità del problema da risolvere;
	- ovviamente aumentare l'efficienza, in quanto non si lavora più in modo sequenziale ma in parallelo;
	- semplificare la programmazione (secondo un modello di scomposizione dell'algoritmo in più parti che possono procedere contemporaneamete).
- i processi possono condividere variabili;
- sono caratterizzati dal fatto che generalmente esistono più processi che processori;
- i processi sono schedulati ed eseguiti indipendentemente.


b) sistemi multitasking/modelli di sistemi distribuiti
non possono condividere variabili, ...
- 
l'interconnessione tra i processi viene garantita tramite un opportuno supporto fornito dal sistema operativo, che mette a disposizione dei processi che devono interagire fra loro, 

non potendo condividere memoria, si scambiano messaggi.

questa organizzazione tipicamente fa riferimento al modello client-server

in alcuni casi (sistema distribuito) ogni parte dell'applicazione che esegue su un nodo distinto della rete, può essere modellata come applicazione multithreaded.

Sistemi ibridi, in cui alcune parti interagiscono in modo multithreaded (memoria comune(?)), altri a scambio di messaggi

c) applicazioni parallele
Possiamo avere sia un modello in cui i processi condividono memoria, o no.
Ciò che caratterizza queste app è l'obbiettivo per le quali vengono procettate: risolvere il problema dato nel modo più veloce dato; oppure risolvere un problema di dimensioni più grandi di quello dato, nello stesso tempo.

Tipicamente quando parliamo di app parallele parliamo di app progettate specificatamente per eseguire su sistemi paralleli (anche a livello hw).

a seconda del modello architetturale, l'esecuzione è portata avanti da istruzioni/thread/processi

abbiamo parti dell'applicazione che eseguono in parallelo
e ci dev'essere la possibilità di mettere in comunicazione queste diverse parti.
Tipicamente vengono utlizzate delle librerie a questo scopo.






